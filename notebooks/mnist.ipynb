{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56V5oun18ZdZ"
   },
   "source": [
    "## Ejercicio práctico Mnist + Tensorboard\n",
    "\n",
    "El objetivo de esta libreta es generar un modelo simple de clasificación de imágenes usando Keras y revisar el rendimiento de los modelos a través de tensorboard.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f7/MnistExamplesModified.png\" width=800 height=400 />\n",
    "\n",
    "- Información adicional: [MNIST](https://en.wikipedia.org/wiki/MNIST_database)\n",
    "- Código fuente: https://www.tensorflow.org/tensorboard/get_started?hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6B95Hb6YVgPZ"
   },
   "outputs": [],
   "source": [
    "# Cargamos la extensión de Tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wqSAZExy6xV"
   },
   "outputs": [],
   "source": [
    "#Carga de bibliotecas\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ao7fJW1Pyiza"
   },
   "outputs": [],
   "source": [
    "#borramos cualquier log previo\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-DHsby18cot"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist #carga de los datos\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data() #Split data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 #normalización de los datos\n",
    "\n",
    "#Creamos la arquitectura de un modelo de clasificación\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28), name='layers_flatten'),\n",
    "    tf.keras.layers.Dense(512, activation='relu', name='layers_dense'),\n",
    "    tf.keras.layers.Dropout(0.2, name='layers_dropout'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='layers_dense_2')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKUjdIoV87um"
   },
   "source": [
    "## Using TensorBoard with Keras Model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAQThq539CEJ"
   },
   "outputs": [],
   "source": [
    "#instancia del modelo\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") #Ubicación para almacenar logs\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#Entrenamineto del modelo\n",
    "model.fit(x=x_train, y=y_train, \n",
    "          epochs=5, validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback]) #nos aseguramos que los logs son creados y almacenados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos el rendimiento del modelo usando TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4UKgTLb9fKI"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCsoUNb6YhGc"
   },
   "source": [
    "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/quickstart_model_fit.png?raw=1\"/> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gi4PaRm39of2"
   },
   "source": [
    "A brief overview of the visualizations created in this example and the dashboards (tabs in top navigation bar) where they can be found:\n",
    "\n",
    "* **Scalars** show how the loss and metrics change with every epoch. You can use them to also track training speed, learning rate, and other scalar values. Scalars can be found in the **Time Series** or **Scalars** dashboards.\n",
    "* **Graphs** help you visualize your model. In this case, the Keras graph of layers is shown which can help you ensure it is built correctly. Graphs can be found in the **Graphs** dashboard.\n",
    "* **Histograms** and **Distributions** show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way. Histograms can be found in the **Time Series** or **Histograms** dashboards. Distributions can be found in the **Distributions** dashboard.\n",
    "\n",
    "Additional TensorBoard dashboards are automatically enabled when you log other types of data. For example, the Keras TensorBoard callback lets you log images and embeddings as well. You can see what other dashboards are available in TensorBoard by clicking on the \"inactive\" dropdown towards the top right."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "get_started.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
